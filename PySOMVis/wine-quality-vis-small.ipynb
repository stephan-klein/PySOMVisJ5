{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4a15c00",
   "metadata": {},
   "source": [
    "# Visualizations small SOM - Wine Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480f3b23",
   "metadata": {},
   "source": [
    "## 1. Hit histogram\n",
    "The hit histogram visualizes the frequency with which neurons get hit during the training of a SOM.\n",
    "\n",
    "We observe the BMU distribution is spread out over large areas of the som (compared to room occupancy) with two peaking areas in the center (-0.2,-0.1) and on left top (-0.45,0.25).\n",
    "We compare different color schemes for the same area, comparing rainbow, a mono sequential (from white to dark red) and a uniform sequential (inferno).\n",
    "\n",
    "We conclude the mono sequential has the best visibility to identify high value clusters quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fef811b",
   "metadata": {},
   "source": [
    "![](img/wine_hit_rainbow.png)\n",
    "\n",
    "![](img/wine_hit_reds.png)\n",
    "\n",
    "![](img/wine_hit_inferno.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cdbc1a",
   "metadata": {},
   "source": [
    "## 2. Smoothed data histogram\n",
    "\n",
    "The SDH is an extension of hit histograms that maps input vectors onto n-best matching units and achieves a smoothing effect.\n",
    "\n",
    "To increase the smoothing we also activated interpolation.\n",
    "\n",
    "We experimented with different smoothing factors. As expected the smoothing factor 1 gives us the same visualization as the hit histogram visualization. Bigger and smoother clusters become visible with higher factors such as 50. \n",
    "With the weighted SDH approach in particular, additional high density clusters emerge more clearly, for example at the bottom (0.2, -0.4)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32e498c",
   "metadata": {},
   "source": [
    "![SDH](img/wine_sdh_1_interpol.png)\n",
    "SDH with smoothing factor 1\n",
    "\n",
    "![SDH weighted factor](img/wine_sdh_50_interpol.png)\n",
    "SDH with smoothing Factor 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2186cb",
   "metadata": {},
   "source": [
    "## 3. Neighbourhood graph\n",
    "\n",
    "Neighbourhood graphs visualize which areas of the SOM are in proximity based on the input space.\n",
    "\n",
    "We plotted the neighbourhood graph for 4 nearest neighbours over a hit histogram and for the neighbors with radius 1 in the input space. In both cases we see a lot of topology violations, but also some local connections on zooming on a cluster.\n",
    "\n",
    "We double-checked the SOM Training and could not determine any issues, even retrained multiple epochs, but fundamentally we did not receive a different result. On inspecting the separate attribute weights (with the component diagram) we see poor correlation throughout the different attributes. We suspect this upon calculation of the BMUs heterogeneous attribute cancel each other out causing the noise in the SOM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224c9c89",
   "metadata": {},
   "source": [
    "![](img/wine_neighbours_knn4.png)\n",
    "KNN 4\n",
    "\n",
    "![](img/wine_neighbours_radius1.png)\n",
    "Radius 1\n",
    "\n",
    "![](img/wine_neighbours_radius1_zoom.png)\n",
    "Radius 1 - Zoomed to a cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e339f2",
   "metadata": {},
   "source": [
    "## 4. Sky Metaphor\n",
    "\n",
    "Sky Metaphor is another density visualization, but maps data items on the exact position within a unit and therefore helps identify similarity between inputs within the same unit or across neighbouring units more accurately.\n",
    "\n",
    "The visualization is more \"irregular\" than other density visualizations since data items are not centered within units anymore. We notice that the image becomes less cloudy with a higher pull factor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2eff1c",
   "metadata": {},
   "source": [
    "![](img/wine_sky_pf_0.25.png)\n",
    "Sky Metaphor - pull factor 0.25\n",
    "\n",
    "![](img/wine_sky_pf_0.5.png)\n",
    "Sky Metaphor - pull factor 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb051501",
   "metadata": {},
   "source": [
    "## 5. Activity Histogram\n",
    "\n",
    "The Activity Histogram per data point visualizes the distance between input vector and all weight vectors.\n",
    "\n",
    "We chose two input vectors: 253 and 2886. We notice the one neuron at coordinates ~(0.4,-0,2) that is consistently red for almost all input vectors. This indicates a high distance in all samples in this area."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8e3b0c",
   "metadata": {},
   "source": [
    "![](img/wine_activityhist_253.png)\n",
    "Activity histogram - Sample 253\n",
    "\n",
    "![](img/wine_activityhist_2886.png)\n",
    "Activity histogram - Sample 2886"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2ae242",
   "metadata": {},
   "source": [
    "## 6. Minimum spanning tree\n",
    "\n",
    "The Minimum Spanning Tree visualizes related nodes on the map by connecting similar nodes with each other.  The weights of the edges are computed by a distance metric between the vectors of the vertices and subsequently minimized.\n",
    "ADD CITATION https://www.ifs.tuwien.ac.at/~mayer/publications/pdf/may_icann10.pdf\n",
    "\n",
    "There are four available settings for the distance in PySOMVis: all, diagonal, direct, MST input data. We could only test it with the All option, due to performance problems on the other options.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03edb1e4",
   "metadata": {},
   "source": [
    "![](img/wine_mspt_all.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f304baf2",
   "metadata": {},
   "source": [
    "## 7. Cluster Connections\n",
    "\n",
    "In this visualization technique, connecting lines are drawn between units based on threshold values. The intensity of the connections between nodes indicates the similarity of underlying data points.\n",
    "\n",
    "We notice for this SOM that there are few clear cluster boundaries, even for higher thresholds such as 50. Only the center-right area stands out with few connections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21936369",
   "metadata": {},
   "source": [
    "![](img/wine_clustercon_0.27.png)\n",
    "Cluster connections - low threshold\n",
    "\n",
    "![](img/wine_clustercon_0.50.png)\n",
    "Cluster connections - high threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cb8689",
   "metadata": {},
   "source": [
    "## 8.U-Matrix\n",
    "The U-Matrix visualization displays the distances between neurons on the SOM grid. Low values correspond to small distances between neighbouring neurons, whereas high values indicate large distances and can be used to identify cluster boundaries. \n",
    "\n",
    "The U-matrix visualization leads to similar findings as previously discussed visualizations. The data is noisy, there is a mix of low and high values across the SOM. There is one identifiable cluster boundary in the center-right region.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcdf51b",
   "metadata": {},
   "source": [
    "![](img/wine_umatrix.png)\n",
    "U-Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5eef26",
   "metadata": {},
   "source": [
    "## 9.D-Matrix\n",
    "The D-Matrix is similar to the U-Matrix, but averages the distance instead of using interpolation.\n",
    "\n",
    "This results in a similar visualisation, but with smoother transitions between \"mountains\" and \"valleys\". The boundaries are therefore not as clear.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d36f36",
   "metadata": {},
   "source": [
    "![](img/wine_dmatrix.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7390bd",
   "metadata": {},
   "source": [
    "## 10.P-Matrix & U*-Matrix\n",
    "\n",
    "Unlike the U-Matrix, P-Matrix is a density and not a distance based metric. It involves estimating the empirical density at each neuron's weight vector in the feature space.\n",
    "\n",
    "The U*-Matrix combines both distance and density information, enhancing cluster visualization by adjusting the U-Matrix with density-derived scale factors.\n",
    "  \n",
    "We see the low density regions (0.5, -0.1) and (-0.4, 0.1) shown in the P-Matrix coincide with high distance regions (U-Matrix) resulting in an overall uniform distribution in the combined visualisation (U*-Matrix)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a38dba5",
   "metadata": {},
   "source": [
    "![](img/wine_pmatrix_p1_r1.8.png)\n",
    "P-Matrix\n",
    "\n",
    "![](img/wine_umatrix_p1_r1.8.png)\n",
    "U*-Matrix\n",
    "\n",
    "![](img/wine_umatrix_p14_r2.8.png)\n",
    "U*-Matrix with higher percentile and radius"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aca686",
   "metadata": {},
   "source": [
    "## 11. Pie chart\n",
    "\n",
    "We plotted the pie chart over a hit histogram and over a U-Matrix.\n",
    "Each quality score in the dataset (target) is mapped to one color as shown in the legend and the pie charts show what classes and their distribution for each unit. We notice classes are distributed over the entire map, no clear trends are visibile, a further display of the general noisyness of the SOM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c86c34aa7b88f3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](img/wine_pie_hhist_full.png)\n",
    "Pie Chart over Hit histogram\n",
    "\n",
    "![](img/wine_pie_umatrix_full.png)\n",
    "Pie Chart over U-Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1caa458",
   "metadata": {},
   "source": [
    "## 12. Chessboard\n",
    "\n",
    "Chessboard visualization is a type of class coloring visualization, combining Voronoi Tesselation and chessboard style pixel coloring according to dominant classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c5aed53a737ebd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](img/wine_chessboardandvoronoi.png)\n",
    "Chessboard visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa89e435",
   "metadata": {},
   "source": [
    "## 13. Component planes\n",
    "The component planes visualization shows the distribution of the weights for the selected attributes across the SOM units. \n",
    "\n",
    "Analysing the component planes visualizations show no apparent correlation between all components.\n",
    "Some component pairs do unsurprisingly correlate, such as residual sugar and sugar, free sulfur oxide and total sulfur oxide or the inversely correlated citric acidity and volatile acidity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6c07c9",
   "metadata": {},
   "source": [
    "![](img/wine_comp_0_fixedacidity.png)\n",
    "Component 0 - Fixed acidity\n",
    "\n",
    "![](img/wine_comp_1_volatile_acidity.png)\n",
    "Component 1 - Volatile acidity\n",
    "\n",
    "![](img/wine_comp_2_citric_acidity.png)\n",
    "Component 2 - Citric acidity\n",
    "\n",
    "![](img/wine_comp_3_residual_sugar.png)\n",
    "Component 3 - Residual sugar\n",
    "\n",
    "![](img/wine_comp_4_chlorides.png)\n",
    "Component 4 - Chlorides\n",
    "\n",
    "![](img/wine_comp_5_free_sulfur_dioxide.png)\n",
    "Component 5 - Free sulfur dioxide\n",
    "\n",
    "![](img/wine_comp_6_total_sulfur_dioxide.png)\n",
    "Component 6 - Total sulfur dioxide\n",
    "\n",
    "![](img/wine_comp_7_density.png)\n",
    "Component 7 - Density\n",
    "\n",
    "![](img/wine_comp_8_pH.png)\n",
    "Component 8 - PH\n",
    "\n",
    "![](img/wine_comp_9_sulphates.png)\n",
    "Component 9 - Sulphates\n",
    "\n",
    "![](img/wine_comp_10_sugar.png)\n",
    "Component 10 - Sugar\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deb2fd9",
   "metadata": {},
   "source": [
    "## 14. Metro Map\n",
    "\n",
    "MetroMap is similar to component planes, but groups weights of the selected attribute into bins.\n",
    "Component lines connect the centers of gravity of each bin.\n",
    "\n",
    "When one attribute is selected with the option of 4 bins, we see how the fixed acidity values are distributed into the bins.\n",
    "\n",
    "If multiple attributes are selected, only one bin is visualized.\n",
    "\n",
    "TODO rework text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc21f0be",
   "metadata": {},
   "source": [
    "![](img/wine_metro_class0_4bins.png)\n",
    "Metro Map - 1 attribute, 4 bins\n",
    "\n",
    "![](img/wine_metro_allclasses_level_0.6.png)\n",
    "Metro Map - all attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfd80fb",
   "metadata": {},
   "source": [
    "## 15. Clustering\n",
    "\n",
    "Clustering is a non-deterministic division of the map into regions based on the weights.\n",
    "There are two approaches: k-means and agglomerative clustering.\n",
    "\n",
    "With a number of 4 clusters we observe that neurons belonging to the same cluster are in relative proximity, with only a couple of outliers. Our main cluster with low sensor data readings is not visualized, however, this can change since clustering is non-deterministic.\n",
    "Increasing the number of clusters we see topology violations again in the neurons belonging to the cluster with low sensor data readings.\n",
    "\n",
    "With agglomerative clustering we see clusters get aggregated, especially the low sensor data cluster.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6973b94",
   "metadata": {},
   "source": [
    "![](img/wine_cluster_kmeans3.png)\n",
    "![](img/wine_cluster_kmeans15.png)\n",
    "![](img/wine_cluster_agglo_ward10.png)\n",
    "![](img/wine_cluster_agglo_complete10.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25f07f5",
   "metadata": {},
   "source": [
    "## 16. Quantization error\n",
    "\n",
    "The visualization shows the average distance between the input vector, and it's best matching unit and serves as an indication of how well the map is trained.\n",
    "\n",
    "We observe only one neuron with a high quantization error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9004d510",
   "metadata": {},
   "source": [
    "![](img/wine_quant_error.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ef2d1e",
   "metadata": {},
   "source": [
    "## 17. Topographic Error\n",
    "\n",
    "The topographic error visualizes how well the SOM preserves the topography of the input\n",
    "space by calculating the percentage of data samples for which the first and second BMU are not placed in adjacent units in the SOM.\n",
    "\n",
    "We notice that the cluster with low sensor readings has a high amount of topographic errors, but the cluster is dense and according to the lecture this might be misleading. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658b488e",
   "metadata": {},
   "source": [
    "![](img/wine_topo_error_4unitnbh.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e7a9ef",
   "metadata": {},
   "source": [
    "## 18. SOMStreamVis\n",
    "\n",
    "The SOMStreamVis plots best matching BMU indexes over time (natural order of samples) and can provide additional information to a SOM visualization.\n",
    "\n",
    "As Wine Quality is not a timeseries the visualisation does not apply for this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8f26cc",
   "metadata": {},
   "source": [
    "## 18. Intrinsic distance\n",
    "\n",
    "Intrinsic distance visualization combines topographic and quantization error visualizations.\n",
    "\n",
    "Due to performance issues, we weren't able to generate the visualization in a reasonable amount on time (On a High performance cloud server with 4 CPUs and 32GB RAM - directly run with python not via jupyter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2a439f",
   "metadata": {},
   "source": [
    "## 19. Mnemonic SOM\n",
    "\n",
    "Due to an error we were unable to render this visualization.\n",
    "ValueError: cannot reshape array of size 4400 into shape (10,10,11)\n",
    "  File \"/home/sklei/miniconda3/envs/sorg2/lib/python3.12/site-packages/param/depends.py\", line 41, in _depends\n",
    "    return func(*args, **kw)\n",
    "           ^^^^^^^^^^^^^^^^^\n",
    "  File \"/home/sklei/PySOMVisJ5/PySOMVis/controls/controllers.py\", line 418, in trainMnemonicSOM\n",
    "    self._calculate()\n",
    "  File \"/home/sklei/PySOMVisJ5/PySOMVis/mnemonics/mnemonicSOM.py\", line 54, in _calculate\n",
    "    self._main._display(UMatrix.calculate_UMatrix(self._weights, self._controls.M, self._controls.N, self._main._dim))\n",
    "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "  File \"/home/sklei/PySOMVisJ5/PySOMVis/visualizations/umatrix.py\", line 35, in calculate_UMatrix\n",
    "    U = weights.reshape(m, n, dim)\n",
    "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "ValueError: cannot reshape array of size 4400 into shape (10,10,11)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
