{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4a15c00",
   "metadata": {},
   "source": [
    "# Visualizations small SOM - Wine Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480f3b23",
   "metadata": {},
   "source": [
    "## 1. Hit histogram\n",
    "The hit histogram visualizes the frequency with which neurons get hit during the training of a SOM.\n",
    "\n",
    "We observe the BMU Distribution is spread out over large areas of the som (compared to room occupancy) with two peaking areas in the center (-0.2,-0.1) and on left top (-0.45,0.25).\n",
    "We compare different color schemes for the same area, comparing rainbow, a mono sequential (from white to dark red) and a uniform sequential (inferno).\n",
    "\n",
    "We conclude the mono sequential has the best visibility to identify high value clusters quickly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fef811b",
   "metadata": {},
   "source": [
    "![](img/wine_hit_rainbow.png)\n",
    "\n",
    "![](img/wine_hit_reds.png)\n",
    "\n",
    "![](img/wine_hit_inferno.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cdbc1a",
   "metadata": {},
   "source": [
    "## 2. Smoothed data histogram\n",
    "\n",
    "The SDH is an extension of hit histograms that maps input vectors onto n-best matching units and achieves a smoothing effect.\n",
    "\n",
    "To increase the smoothing we also activated interpolation.\n",
    "\n",
    "We experimented with different smoothing factors. As expected the smoothing factor 1 gives us the same visualization as the hit histogram visualization. Bigger and smoother clusters become visible with higher factors such as 50. \n",
    "With the weighted SDH approach in particular, additional high densitiy clusters emerge more clearly, for example at the bottom (0.2, -0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32e498c",
   "metadata": {},
   "source": [
    "![SDH](img/wine_sdh_1_interpol.png)\n",
    "Smoothing Factor 1\n",
    "\n",
    "![SDH weighted factor](img/wine_sdh_50_interpol.png)\n",
    "Smoothing Factor 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2186cb",
   "metadata": {},
   "source": [
    "## 3. Neighbourhood graph\n",
    "\n",
    "Neighbourhood graphs visualize which areas of the SOM are in proximity based on the input space.\n",
    "\n",
    "We plotted the neighbourhood graph for 4 nearest neighbours over a hit histogram and for the neighbors with radius 1 in the input space. In both cases we see a lot of topology violations, but also some local connections on zooming on a cluster.\n",
    "\n",
    "We doublechecked the SOM Training and could not determine any issues, even retrained multiple epochs but fundamentally we did not receive a different result. On inspecting the separate attribute weights (with the component diagram) we see poor correlation throughout the different attributes. We suspect this upon calculation of the BMUs inhomogenous attribute cancel each other out causing the noise in the SOM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224c9c89",
   "metadata": {},
   "source": [
    "![](img/wine_neighbours_knn4.png)\n",
    "KNN 4\n",
    "\n",
    "![](img/wine_neighbours_radius1.png)\n",
    "Radius 1\n",
    "\n",
    "![](img/wine_neighbours_radius1_zoom.png)\n",
    "Radius 1 - Zoomed to a cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e339f2",
   "metadata": {},
   "source": [
    "## 4. Sky Metaphor\n",
    "\n",
    "Sky Metaphor is another density visualization, but maps data items on the exact position within a unit and therefore helps identify similarity between inputs within the same unit or across neighbouring units more accurately.\n",
    "\n",
    "The visualization is more \"irregular\" than other density visualizations since data items are not centered within units anymore.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2eff1c",
   "metadata": {},
   "source": [
    "![](img/occs_skymetaphor.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb051501",
   "metadata": {},
   "source": [
    "## 5. Activity Histogram\n",
    "\n",
    "The Activity Histogram per data point visualizes the distance between input vector and all weight vectors.\n",
    "\n",
    "We chose two input vectors: 0 and 816. Sample 0 represents a sample with low sensor readings as opposed to sample 816 which has high sensor readings.\n",
    "Sample 0 shows cluster homogeneity, while sample 816 reveals some topology violations in the high sensor readings cluster indicating cluster substructures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8e3b0c",
   "metadata": {},
   "source": [
    "![](img/occs_acthistogram_0.png)\n",
    "![](img/occs_acthistogram_816.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2ae242",
   "metadata": {},
   "source": [
    "## 6. Minimum spanning tree\n",
    "\n",
    "The Minimum Spanning Tree visualizes related nodes on the map by connecting similar nodes with each other.  The weights of the edges are computed by a distance metric between the vectors of the vertices and subsequently minimized.\n",
    "ADD CITATION https://www.ifs.tuwien.ac.at/~mayer/publications/pdf/may_icann10.pdf\n",
    "\n",
    "There are four available settings for the distance in PySOMVis: all, diagonal, direct, MST input data. We could only test it with the All option, due to performance problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03edb1e4",
   "metadata": {},
   "source": [
    "![](img/occs_mspt_all.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f304baf2",
   "metadata": {},
   "source": [
    "## 7. Cluster Connections\n",
    "\n",
    "In this visualization technique, connecting lines are drawn between units based on threshold values.\n",
    "\n",
    "We observe that with a certain threshold combination we can clearly see the cluster structures. If the thresholds are too low, the clusters are not as distinctly visible in the visualization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21936369",
   "metadata": {},
   "source": [
    "![](img/occs_cluster_connections-0.22.png)\n",
    "![](img/occs_cluster_connections-0.33.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cb8689",
   "metadata": {},
   "source": [
    "## 8.U-Matrix\n",
    "The U-Matrix visualization displays the distances between neurons on the SOM grid. Low values correspond to small distances between neighbouring neurons, whereas high values indicate large distances and can be used to identify cluster boundaries. \n",
    "\n",
    "The visualization helps to discern individual cluster structures that appeared unclear in earlier visualizations.\n",
    " Especially the clusters with low sensor reading values form coherent regions(valleys) with visible cluster boundaries in the U-matrix. The regions with high sensor readings (assuming high occupancy) do not form coherent, but noisy regions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcdf51b",
   "metadata": {},
   "source": [
    "![](img/occs_umatrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5eef26",
   "metadata": {},
   "source": [
    "## 9.D-Matrix\n",
    "The D-Matrix is similar to the U-Matrix, but averages the distance instead of using interpolation.\n",
    "\n",
    "This results in a similar visualisation, but with smoother transitions between \"mountains\" and \"valleys\". The boundaries are therefore not as clear.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d36f36",
   "metadata": {},
   "source": [
    "![](img/occs_dmatrix.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7390bd",
   "metadata": {},
   "source": [
    "## 10.P-Matrix & U*-Matrix\n",
    "\n",
    "Unlike the U-Matrix, P-Matrix is a density and not a distance based metric. It involves estimating the empirical density at each neuron's weight vector in the feature space.\n",
    "\n",
    "The U*-Matrix combines both distance and density information, enhancing cluster visualization by adjusting the U-Matrix with density-derived scale factors.\n",
    "  \n",
    "We experimented with higher percentile values, and thus higher radius.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a38dba5",
   "metadata": {},
   "source": [
    "![](img/occs_pmatrix.png)\n",
    "![](img/occs_ustarmatrix.png)\n",
    "![](img/occs_ustarmatrix_doublepercentile.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aca686",
   "metadata": {},
   "source": [
    "## 11. Pie chart\n",
    "\n",
    "This visualization is for classification type datasets. The room occupancy provides the occupancy count as an integer type target, which is not suitable for this classification type\n",
    " visualization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1caa458",
   "metadata": {},
   "source": [
    "## 12. Chessboard\n",
    "\n",
    "Chessboard visualization is a type of class coloring visualization, combining Voronoi Tesselation and chessboard style pixel coloring according to dominant classes.\n",
    "\n",
    "Since the dataset is not suitable for classification type visualizations, we didn't use this visualization on the room occupancy data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa89e435",
   "metadata": {},
   "source": [
    "## 13. Component planes\n",
    "The component planes visualization shows the distribution of the weights for the selected attributes across the SOM units. \n",
    "\n",
    "The component plane visualization contains two clusters for every light attribute coming from the sensors s1-s4. We can observe a positive correlation with the visualizations of the other attributes such as temperature, sound, PIR. Analysing this together with the visualization for the time of day together with the sensor readings with high values (temperature, co2, motion) point to a higher occupancy during evenings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6c07c9",
   "metadata": {},
   "source": [
    "![](img/occs_comp_temp.png)\n",
    "![](img/occs_comp_light.png)\n",
    "![](img/occs_comp_sound.png)\n",
    "![](img/occs_comp_co2.png)\n",
    "![](img/occs_comp_pir.png)\n",
    "![](img/occs_comp_timeofday.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deb2fd9",
   "metadata": {},
   "source": [
    "## 14. Metro Map\n",
    "\n",
    "MetroMap is similar to component planes, but groups weights of the selected attribute into bins.\n",
    "Component lines connect the centers of gravity of each bin.\n",
    "\n",
    "When one attribute is selected with the option of 5 bins, we see how the temperature readings from the one sensor are distributed into the bins.\n",
    "\n",
    "If multiple attributes are selected, only one bin is visualized and the gradients of most attributes are very similar going from the cluster with high sensor readings to the one with low sensor readings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc21f0be",
   "metadata": {},
   "source": [
    "![](img/occs_metromap_attr1.png)\n",
    "![](img/occs_metromap_allattr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfd80fb",
   "metadata": {},
   "source": [
    "## 15. Clustering\n",
    "\n",
    "Clustering is a non-deterministic division of the map into regions based on the weights.\n",
    "There are two approaches: k-means and agglomerative clustering.\n",
    "\n",
    "With a number of 4 clusters we observe that neurons belonging to the same cluster are in relative proximity, with only a couple of outliers. Our main cluster with low sensor data readings is not visualized, however, this can change since clustering is non-deterministic.\n",
    "Increasing the number of clusters we see topology violations again in the neurons belonging to the cluster with low sensor data readings.\n",
    "\n",
    "With agglomerative clustering we see clusters get aggregated, especially the low sensor data cluster.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6973b94",
   "metadata": {},
   "source": [
    "![](img/occs_clusters_4.png)\n",
    "![](img/occs_clusters_8.png)\n",
    "![](img/occs_clusters_agglo_ward8.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25f07f5",
   "metadata": {},
   "source": [
    "## 16. Quantization error\n",
    "\n",
    "The visualization shows the average distance between the input vector, and it's best matching unit and serves as an indication of how well the map is trained.\n",
    "\n",
    "We observe only one neuron with a high quantization error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9004d510",
   "metadata": {},
   "source": [
    "![](img/occs_quant_error.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ef2d1e",
   "metadata": {},
   "source": [
    "## 17. Topographic Error\n",
    "\n",
    "The topographic error visualizes how well the SOM preserves the topography of the input\n",
    "space by calculating the percentage of data samples for which the first and second BMU are not placed in adjacent units in the SOM.\n",
    "\n",
    "We notice that the cluster with low sensor readings has a high amount of topographic errors, but the cluster is dense and according to the lecture this might be misleading. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658b488e",
   "metadata": {},
   "source": [
    "![](img/occs_toperror.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e7a9ef",
   "metadata": {},
   "source": [
    "## 18. SOMStreamVis\n",
    "\n",
    "The SOMStreamVis plots best matching BMU indexes over time (natural order of samples) and can provide additional information to a SOM visualization.\n",
    "\n",
    "We used the SOMStreamVis together with the Clustering visualization. Colors are therefore matched between cluster and the matching BMUs over time.\n",
    "The dataset contains information from the 22.12. starting at 11 am until the 26.12. at 9 am, followed by a gap until the 10.01. 15:30 (at sample number 8086) and ending on the 11.01. at 9am.\n",
    "SOMStreamVis reflects patterns in the readings, data that belongs to the cluster with low sensor readings match samples from the nights and the high sensor readings are found in samples from afternoons and evenings. The 25.12. is an outlier in the sense that there is no match with the high sensor reading cluster in the afternoon/evening, indicating low occupancy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed56dc90",
   "metadata": {},
   "source": [
    "![](img/occs_somviz_clusters.png)\n",
    "![](img/occs_somviz_timeline.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8f26cc",
   "metadata": {},
   "source": [
    "## 18. Intrinsic distance\n",
    "\n",
    "Intrinsic distance visualization combines topographic and quantization error visualizations.\n",
    "\n",
    "Due to performance issues or a bug, we weren't able to display the visualization. According to the logging we have built into it, the calculate function never terminated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2a439f",
   "metadata": {},
   "source": [
    "## 19. Mnemonic SOM\n",
    "\n",
    "Due to performance issues on this dataset, we were unable to render this visualization. The logging we additionally implemented indicated that the calculate function never terminated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
